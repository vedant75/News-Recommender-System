{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vedant75/News-Recommender-System/blob/main/MIND_GNN_Recommender.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-geometric\n",
        "!pip install torch-scatter"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mvaB9tXg4YWa",
        "outputId": "37d1a036-2da0-4bfa-8fa3-2bca0183c22b"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-geometric\n",
            "  Downloading torch_geometric-2.7.0-py3-none-any.whl.metadata (63 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/63.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.7/63.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: aiohttp in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.13.2)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2025.3.0)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.1.6)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.0.2)\n",
            "Requirement already satisfied: psutil>=5.8.0 in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (5.9.5)\n",
            "Requirement already satisfied: pyparsing in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.2.5)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (4.67.1)\n",
            "Requirement already satisfied: xxhash in /usr/local/lib/python3.12/dist-packages (from torch-geometric) (3.6.0)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.5.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.4.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.4.0)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (25.4.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.8.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (6.7.0)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (0.4.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.12/dist-packages (from aiohttp->torch-geometric) (1.22.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2->torch-geometric) (3.0.3)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.4.4)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (3.11)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->torch-geometric) (2025.11.12)\n",
            "Requirement already satisfied: typing-extensions>=4.2 in /usr/local/lib/python3.12/dist-packages (from aiosignal>=1.4.0->aiohttp->torch-geometric) (4.15.0)\n",
            "Downloading torch_geometric-2.7.0-py3-none-any.whl (1.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m81.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: torch-geometric\n",
            "Successfully installed torch-geometric-2.7.0\n",
            "Collecting torch-scatter\n",
            "  Downloading torch_scatter-2.1.2.tar.gz (108 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.0/108.0 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Building wheels for collected packages: torch-scatter\n",
            "  Building wheel for torch-scatter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-scatter: filename=torch_scatter-2.1.2-cp312-cp312-linux_x86_64.whl size=3856999 sha256=418eefc20bdc3f6fe63a6b2f396311470c5dc24eea275c55ea926f8d0830fcf2\n",
            "  Stored in directory: /root/.cache/pip/wheels/84/20/50/44800723f57cd798630e77b3ec83bc80bd26a1e3dc3a672ef5\n",
            "Successfully built torch-scatter\n",
            "Installing collected packages: torch-scatter\n",
            "Successfully installed torch-scatter-2.1.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch-sparse"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g908AASt8aFq",
        "outputId": "cb9d99ce-e826-498a-bec7-544631e590e8"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torch-sparse\n",
            "  Downloading torch_sparse-0.6.18.tar.gz (209 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/210.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m210.0/210.0 kB\u001b[0m \u001b[31m9.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.12/dist-packages (from torch-sparse) (1.16.3)\n",
            "Requirement already satisfied: numpy<2.6,>=1.25.2 in /usr/local/lib/python3.12/dist-packages (from scipy->torch-sparse) (2.0.2)\n",
            "Building wheels for collected packages: torch-sparse\n",
            "  Building wheel for torch-sparse (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for torch-sparse: filename=torch_sparse-0.6.18-cp312-cp312-linux_x86_64.whl size=3039809 sha256=5821a6afb33ad228c1c2524c60ba18470ef8234be9fd8fbab3e1b7ed2ebadb77\n",
            "  Stored in directory: /root/.cache/pip/wheels/71/fa/21/bd1d78ce1629aec4ecc924a63b82f6949dda484b6321eac6f2\n",
            "Successfully built torch-sparse\n",
            "Installing collected packages: torch-sparse\n",
            "Successfully installed torch-sparse-0.6.18\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import requests\n",
        "import zipfile\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch_geometric.data import HeteroData\n",
        "from torch_geometric.nn import SAGEConv, GATConv, LGConv, to_hetero\n",
        "from torch_geometric.transforms import RandomLinkSplit, ToUndirected\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch.nn import ModuleList"
      ],
      "metadata": {
        "id": "CzG4qG8MErL0"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"arashnic/mind-news-dataset\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AEff2l01ZfiR",
        "outputId": "a587501e-5c56-4d1c-ee8f-60491ca9b3cf"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/arashnic/mind-news-dataset?dataset_version_number=2...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 61.7M/61.7M [00:04<00:00, 15.2MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/arashnic/mind-news-dataset/versions/2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "CONFIG = {\n",
        "    'hidden_channels': 32,\n",
        "    'num_layers': 2,\n",
        "    'epochs': 20,\n",
        "    'batch_size': 256,\n",
        "    'lr': 0.001,\n",
        "    'weight_decay': 1e-5,\n",
        "    'model_type': 'GAT',\n",
        "    'heads': 2,\n",
        "    'device': torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "}"
      ],
      "metadata": {
        "id": "LIT9dvn7UL-w"
      },
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def find_dataset_files(root_path):\n",
        "    \"\"\"\n",
        "    Recursively searches for the MINDsmall_train data files.\n",
        "    The dataset structure can vary (sometimes zipped, sometimes extracted folders).\n",
        "    \"\"\"\n",
        "    print(f\"Searching for training data in {root_path}...\")\n",
        "\n",
        "    target_files = {'behaviors.tsv', 'news.tsv'}\n",
        "\n",
        "    for root, dirs, files in os.walk(root_path):\n",
        "        if 'MINDsmall_train' in root:\n",
        "            if target_files.issubset(set(files)):\n",
        "                print(f\"Found MINDsmall_train data at: {root}\")\n",
        "                return root\n",
        "\n",
        "    for root, dirs, files in os.walk(root_path):\n",
        "        if target_files.issubset(set(files)):\n",
        "            if 'train' in root.lower() or 'small' in root.lower():\n",
        "                print(f\"Found compatible training data at: {root}\")\n",
        "                return root\n",
        "\n",
        "    raise FileNotFoundError(\"Could not locate 'behaviors.tsv' and 'news.tsv' in the downloaded files.\")\n",
        "\n",
        "def load_mind_data(data_path):\n",
        "    behaviors_path = os.path.join(data_path, 'behaviors.tsv')\n",
        "    news_path = os.path.join(data_path, 'news.tsv')\n",
        "\n",
        "    # Load News Data\n",
        "    news_df = pd.read_csv(\n",
        "        news_path,\n",
        "        sep='\\t',\n",
        "        header=None,\n",
        "        names=['news_id', 'category', 'subcategory', 'title', 'abstract', 'url', 'title_entities', 'abstract_entities'],\n",
        "        quoting=3,\n",
        "        on_bad_lines='skip'\n",
        "    )\n",
        "\n",
        "    # Load Behaviors Data\n",
        "    behaviors_df = pd.read_csv(\n",
        "        behaviors_path,\n",
        "        sep='\\t',\n",
        "        header=None,\n",
        "        names=['impression_id', 'user_id', 'time', 'history', 'impressions']\n",
        "    )\n",
        "\n",
        "    # --- Mappings ---\n",
        "    unique_news = news_df['news_id'].unique()\n",
        "    news_id_map = {nid: i for i, nid in enumerate(unique_news)}\n",
        "    num_news = len(unique_news)\n",
        "\n",
        "    unique_users = behaviors_df['user_id'].unique()\n",
        "    user_id_map = {uid: i for i, uid in enumerate(unique_users)}\n",
        "    num_users = len(unique_users)\n",
        "\n",
        "    unique_categories = news_df['category'].unique()\n",
        "    category_map = {cat: i for i, cat in enumerate(unique_categories)}\n",
        "    num_categories = len(unique_categories)\n",
        "\n",
        "    # --- Node Features ---\n",
        "    print(\"Building Node Features...\")\n",
        "    news_features = torch.zeros((num_news, num_categories))\n",
        "    for _, row in news_df.iterrows():\n",
        "        if row['news_id'] in news_id_map and row['category'] in category_map:\n",
        "            nid_idx = news_id_map[row['news_id']]\n",
        "            cat_idx = category_map[row['category']]\n",
        "            news_features[nid_idx, cat_idx] = 1.0\n",
        "\n",
        "    # --- Edge Construction ---\n",
        "    src = []\n",
        "    dst = []\n",
        "\n",
        "    print(\"Processing interaction history to build graph (this might take a moment)...\")\n",
        "    behaviors_df = behaviors_df.dropna(subset=['history'])\n",
        "\n",
        "    user_ids_series = behaviors_df['user_id'].values\n",
        "    histories_series = behaviors_df['history'].values\n",
        "\n",
        "    for i in range(len(user_ids_series)):\n",
        "        u_id = user_ids_series[i]\n",
        "        hist_str = histories_series[i]\n",
        "\n",
        "        if u_id in user_id_map:\n",
        "            u_idx = user_id_map[u_id]\n",
        "            clicked_news_ids = str(hist_str).split()\n",
        "\n",
        "            for news_id in clicked_news_ids:\n",
        "                if news_id in news_id_map:\n",
        "                    n_idx = news_id_map[news_id]\n",
        "                    src.append(u_idx)\n",
        "                    dst.append(n_idx)\n",
        "\n",
        "    edge_index = torch.tensor([src, dst], dtype=torch.long)\n",
        "\n",
        "    # --- Create HeteroData Object ---\n",
        "    data = HeteroData()\n",
        "    data['user'].num_nodes = num_users\n",
        "    data['user'].node_id = torch.arange(num_users)\n",
        "    data['news'].num_nodes = num_news\n",
        "    data['news'].x = news_features\n",
        "    data['news'].node_id = torch.arange(num_news)\n",
        "    data['user', 'clicks', 'news'].edge_index = edge_index\n",
        "\n",
        "    data = ToUndirected()(data)\n",
        "\n",
        "    return data, num_users, num_news, user_id_map, news_id_map, news_df"
      ],
      "metadata": {
        "id": "WNLDk6gcaA0Q"
      },
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class GNN(nn.Module):\n",
        "    def __init__(self, hidden_channels, num_layers, conv_type):\n",
        "        super().__init__()\n",
        "        self.num_layers = num_layers\n",
        "        self.conv_type = conv_type\n",
        "\n",
        "        if conv_type == \"SAGE\":\n",
        "            self.convs = ModuleList(SAGEConv(hidden_channels, hidden_channels) for _ in range(num_layers))\n",
        "        elif conv_type == \"GAT\":\n",
        "            self.convs = ModuleList(GATConv(hidden_channels, hidden_channels, heads=CONFIG['heads'], concat=False, add_self_loops=False) for _ in range(num_layers))\n",
        "        elif conv_type == \"LG\":\n",
        "            self.convs = ModuleList(LGConv() for _ in range(num_layers))\n",
        "\n",
        "    def forward(self, x_dict, edge_index_dict):\n",
        "        if self.conv_type == \"LG\":\n",
        "            # Manual Homogeneous conversion for LightGCN\n",
        "            x_user = x_dict['user']\n",
        "            x_news = x_dict['news']\n",
        "            x = torch.cat([x_user, x_news], dim=0)\n",
        "\n",
        "            edge_index_user_news = edge_index_dict[('user', 'clicks', 'news')]\n",
        "            num_users = x_user.size(0)\n",
        "            src = edge_index_user_news[0]\n",
        "            dst = edge_index_user_news[1] + num_users\n",
        "\n",
        "            edge_index = torch.cat([\n",
        "                torch.stack([src, dst], dim=0),\n",
        "                torch.stack([dst, src], dim=0)\n",
        "            ], dim=1)\n",
        "\n",
        "            for i in range(self.num_layers):\n",
        "                x = self.convs[i](x, edge_index)\n",
        "\n",
        "            x_user_out = x[:num_users]\n",
        "            x_news_out = x[num_users:]\n",
        "            return {'user': x_user_out, 'news': x_news_out}\n",
        "        else:\n",
        "            pass\n",
        "\n",
        "class StandardGNN(nn.Module):\n",
        "    \"\"\"Standard GNN Wrapper for SAGE/GAT to be converted by to_hetero\"\"\"\n",
        "    def __init__(self, hidden_channels, num_layers, conv_type):\n",
        "        super().__init__()\n",
        "        self.conv_type = conv_type\n",
        "        self.num_layers = num_layers\n",
        "        if conv_type == \"SAGE\":\n",
        "            self.convs = ModuleList(SAGEConv(hidden_channels, hidden_channels) for _ in range(num_layers))\n",
        "        elif conv_type == \"GAT\":\n",
        "             self.convs = ModuleList(GATConv(hidden_channels, hidden_channels, heads=CONFIG['heads'], concat=False, add_self_loops=False) for _ in range(num_layers))\n",
        "\n",
        "    def forward(self, x, edge_index):\n",
        "        for i in range(self.num_layers):\n",
        "            x = self.convs[i](x, edge_index)\n",
        "            # Removed F.relu to resolve tracing issue with to_hetero\n",
        "            # if i < self.num_layers - 1:\n",
        "            #     x = F.relu(x)\n",
        "        return x\n",
        "\n",
        "class Classifier(nn.Module):\n",
        "    def forward(self, x_user: torch.Tensor, x_news: torch.Tensor, edge_label_index: torch.Tensor) -> torch.Tensor:\n",
        "        edge_feat_user = x_user[edge_label_index[0]]\n",
        "        edge_feat_news = x_news[edge_label_index[1]]\n",
        "        return (edge_feat_user * edge_feat_news).sum(dim=-1)\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, hidden_channels, data, num_layers=2, conv_type=\"SAGE\"):\n",
        "        super().__init__()\n",
        "        self.conv_type = conv_type\n",
        "\n",
        "        self.news_lin = nn.Linear(data['news'].x.size(1), hidden_channels)\n",
        "        self.news_emb = nn.Embedding(data['news'].num_nodes, hidden_channels)\n",
        "        self.user_emb = nn.Embedding(data['user'].num_nodes, hidden_channels)\n",
        "\n",
        "        if conv_type == \"LG\":\n",
        "            self.gnn = GNN(hidden_channels, num_layers, conv_type)\n",
        "        else:\n",
        "            base_gnn = StandardGNN(hidden_channels, num_layers, conv_type)\n",
        "            self.gnn = to_hetero(base_gnn, data.metadata(), aggr='mean')\n",
        "\n",
        "        self.classifier = Classifier()\n",
        "\n",
        "    def forward(self, data):\n",
        "        x_dict = self.get_embeddings(data)\n",
        "        pred = self.classifier(\n",
        "            x_dict['user'],\n",
        "            x_dict['news'],\n",
        "            data['user', 'clicks', 'news'].edge_label_index\n",
        "        )\n",
        "        return pred\n",
        "\n",
        "    def get_embeddings(self, data):\n",
        "        x_news = self.news_lin(data['news'].x) + self.news_emb(data['news'].node_id)\n",
        "        x_user = self.user_emb(data['user'].node_id)\n",
        "        x_dict = {'user': x_user, 'news': x_news}\n",
        "\n",
        "        # Apply GNN\n",
        "        x_dict = self.gnn(x_dict, data.edge_index_dict)\n",
        "        return x_dict\n",
        "\n",
        "# Updated BPR Loss to match blog (Added regularization)\n",
        "def bpr_loss(user_emb, news_emb, pos_edge_index, neg_edge_index, lambda_reg=1e-4):\n",
        "    pos_scores = (user_emb[pos_edge_index[0]] * news_emb[pos_edge_index[1]]).sum(dim=-1)\n",
        "\n",
        "    min_len = min(pos_scores.size(0), neg_edge_index.size(1))\n",
        "    pos_scores = pos_scores[:min_len]\n",
        "    neg_edge_index = neg_edge_index[:, :min_len]\n",
        "\n",
        "    neg_scores = (user_emb[neg_edge_index[0]] * news_emb[neg_edge_index[1]]).sum(dim=-1)\n",
        "\n",
        "    # BPR Loss + Regularization\n",
        "    loss_bpr = -torch.log(torch.sigmoid(pos_scores - neg_scores) + 1e-15).mean()\n",
        "    loss_reg = lambda_reg * (user_emb[pos_edge_index[0]].norm(2).pow(2) +\n",
        "                             news_emb[pos_edge_index[1]].norm(2).pow(2)) / float(min_len)\n",
        "\n",
        "    return loss_bpr + loss_reg\n",
        "\n",
        "def random_negative_sampling(edge_index, num_news, num_neg_samples=None):\n",
        "    users = edge_index[0]\n",
        "    if num_neg_samples is None:\n",
        "        num_neg_samples = users.size(0)\n",
        "    neg_news = torch.randint(0, num_news, (num_neg_samples,), device=edge_index.device)\n",
        "    neg_edge_index = torch.stack([users, neg_news], dim=0)\n",
        "    return neg_edge_index"
      ],
      "outputs": [],
      "execution_count": 49,
      "metadata": {
        "id": "WFsJC-dC4VEx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def main():\n",
        "    train_dir_path = find_dataset_files(path)\n",
        "    data, num_users, num_news, user_map, news_map, news_df = load_mind_data(train_dir_path)\n",
        "\n",
        "    print(f\"Data Loaded: {num_users} Users, {num_news} Articles\")\n",
        "\n",
        "    print(\"--- 3. Splitting Data (Train/Val/Test) ---\")\n",
        "    transform = RandomLinkSplit(\n",
        "        num_val=0.1,\n",
        "        num_test=0.1,\n",
        "        neg_sampling_ratio=1.0,\n",
        "        edge_types=[('user', 'clicks', 'news')],\n",
        "        rev_edge_types=[('news', 'rev_clicks', 'user')],\n",
        "        is_undirected=True,\n",
        "        add_negative_train_samples=False\n",
        "    )\n",
        "\n",
        "    train_data, val_data, test_data = transform(data)\n",
        "\n",
        "    device = CONFIG['device']\n",
        "    train_data = train_data.to(device)\n",
        "    val_data = val_data.to(device)\n",
        "    test_data = test_data.to(device)\n",
        "\n",
        "    print(f\"--- 4. Initializing {CONFIG['model_type']} Model (Heads={CONFIG['heads']}) ---\")\n",
        "    model = Model(\n",
        "        hidden_channels=CONFIG['hidden_channels'],\n",
        "        data=data,\n",
        "        num_layers=CONFIG['num_layers'],\n",
        "        conv_type=CONFIG['model_type']\n",
        "    ).to(device)\n",
        "\n",
        "    optimizer = torch.optim.Adam(model.parameters(), lr=CONFIG['lr'], weight_decay=CONFIG['weight_decay'])\n",
        "\n",
        "    print(f\"--- 5. Training Loop ({CONFIG['epochs']} Epochs) ---\")\n",
        "    for epoch in range(1, CONFIG['epochs'] + 1):\n",
        "        model.train()\n",
        "\n",
        "        x_dict = model.get_embeddings(train_data)\n",
        "        pos_edge_index = train_data['user', 'clicks', 'news'].edge_label_index\n",
        "        neg_edge_index = random_negative_sampling(\n",
        "            pos_edge_index,\n",
        "            num_news,\n",
        "            num_neg_samples=pos_edge_index.size(1)\n",
        "        )\n",
        "\n",
        "        loss = bpr_loss(x_dict['user'], x_dict['news'], pos_edge_index, neg_edge_index)\n",
        "\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # Validation\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            val_preds = model(val_data)\n",
        "            val_labels = val_data['user', 'clicks', 'news'].edge_label\n",
        "            auc = roc_auc_score(val_labels.cpu().numpy(), val_preds.sigmoid().cpu().numpy())\n",
        "\n",
        "        print(f\"Epoch {epoch:02d} | Loss: {loss.item():.4f} | Val AUC: {auc:.4f}\")\n",
        "\n",
        "    print(\"--- 6. Final Evaluation (Test Set) ---\")\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        test_preds = model(test_data)\n",
        "        test_labels = test_data['user', 'clicks', 'news'].edge_label\n",
        "        auc = roc_auc_score(test_labels.cpu().numpy(), test_preds.sigmoid().cpu().numpy())\n",
        "\n",
        "    print(f\"Test AUC: {auc:.4f}\")\n",
        "\n",
        "    # --- Recall@1000 Calculation (Batched) ---\n",
        "    print(\"--- 7. Generating Top-K Recommendations (Recall@1000) ---\")\n",
        "    k = 1000\n",
        "    num_eval_users = 100\n",
        "    user_indices = test_data['user'].node_id[:num_eval_users]\n",
        "\n",
        "    embeddings = model.get_embeddings(test_data)\n",
        "    user_emb = embeddings['user'][user_indices]\n",
        "    news_emb = embeddings['news']\n",
        "\n",
        "    recall_hits = 0\n",
        "\n",
        "    # Batch processing for similarity to avoid OOM\n",
        "    batch_size = 10 # Process 10 users at a time\n",
        "    print(f\"Calculating Recall@{k} for {num_eval_users} users...\")\n",
        "\n",
        "    for i in range(0, num_eval_users, batch_size):\n",
        "        end = min(i + batch_size, num_eval_users)\n",
        "        batch_user_emb = user_emb[i:end]\n",
        "\n",
        "        # Matrix multiplication: [Batch, Hidden] @ [Hidden, News] -> [Batch, News]\n",
        "        scores = torch.matmul(batch_user_emb, news_emb.t())\n",
        "\n",
        "        # Get Top K\n",
        "        _, top_indices = torch.topk(scores, k=k)\n",
        "\n",
        "        # Check against ground truth (Test Edges)\n",
        "        current_user_ids = user_indices[i:end].cpu().numpy()\n",
        "\n",
        "        # Filter test edges for these users\n",
        "        test_edges = test_data['user', 'clicks', 'news'].edge_label_index\n",
        "        test_labels = test_data['user', 'clicks', 'news'].edge_label\n",
        "        # We only care about positive edges in test set\n",
        "        pos_mask = test_labels == 1\n",
        "        pos_test_edges = test_edges[:, pos_mask]\n",
        "\n",
        "        for idx, u_id in enumerate(current_user_ids):\n",
        "            mask = pos_test_edges[0] == u_id\n",
        "            true_items = pos_test_edges[1][mask].cpu().numpy()\n",
        "\n",
        "            if len(true_items) == 0:\n",
        "                continue\n",
        "\n",
        "            # Check overlap\n",
        "            recs = top_indices[idx].cpu().numpy()\n",
        "            hits = np.intersect1d(true_items, recs)\n",
        "            if len(hits) > 0:\n",
        "                recall_hits += 1\n",
        "\n",
        "    recall_score = recall_hits / num_eval_users\n",
        "    print(f\"Recall@{k} (Sampled): {recall_score:.4f}\")\n",
        "\n",
        "    # Show actual recommendations for the first user in the batch\n",
        "    int_to_newsid = {v: k for k, v in news_map.items()}\n",
        "    newsid_to_title = pd.Series(news_df.title.values, index=news_df.news_id).to_dict()\n",
        "\n",
        "    print(f\"\\nTop 10 Recommendations for User {user_indices[0].item()}:\")\n",
        "    recs = top_indices[0].cpu().numpy()[:10]\n",
        "    for news_idx in recs:\n",
        "        nid = int_to_newsid.get(news_idx, \"Unknown\")\n",
        "        title = newsid_to_title.get(nid, \"Unknown Title\")\n",
        "        print(f\" - [{nid}] {title[:60]}...\")"
      ],
      "metadata": {
        "id": "j0Ur7Lp_Z2K1"
      },
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 669
        },
        "id": "F3Hj_tWuZ2_F",
        "outputId": "221530f8-ebdd-4e25-f29e-6f983928f4ba"
      },
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Searching for training data in /root/.cache/kagglehub/datasets/arashnic/mind-news-dataset/versions/2...\n",
            "Found MINDsmall_train data at: /root/.cache/kagglehub/datasets/arashnic/mind-news-dataset/versions/2/MINDsmall_train\n",
            "Building Node Features...\n",
            "Processing interaction history to build graph (this might take a moment)...\n",
            "Data Loaded: 50000 Users, 51282 Articles\n",
            "--- 3. Splitting Data (Train/Val/Test) ---\n",
            "--- 4. Initializing GAT Model (Heads=2) ---\n",
            "--- 5. Training Loop (20 Epochs) ---\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "OutOfMemoryError",
          "evalue": "CUDA out of memory. Tried to allocate 998.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 244.12 MiB is free. Process 10445 has 14.50 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 252.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
            "\u001b[0;32m/tmp/ipython-input-3832242952.py\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m     \u001b[0mmain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/tmp/ipython-input-116233465.py\u001b[0m in \u001b[0;36mmain\u001b[0;34m()\u001b[0m\n\u001b[1;32m     46\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_embeddings\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m         \u001b[0mpos_edge_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clicks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'news'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_label_index\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         neg_edge_index = random_negative_sampling(\n",
            "\u001b[0;32m/tmp/ipython-input-968133283.py\u001b[0m in \u001b[0;36mget_embeddings\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m# Apply GNN\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mx_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0medge_index_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mx_dict\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36mcall_wrapped\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    835\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    836\u001b[0m         \u001b[0;32mdef\u001b[0m \u001b[0mcall_wrapped\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 837\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    838\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    839\u001b[0m         \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_wrapped\u001b[0m  \u001b[0;31m# type: ignore[method-assign]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    411\u001b[0m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# noqa: B904\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m                 \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/fx/graph_module.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, obj, *args, **kwargs)\u001b[0m\n\u001b[1;32m    398\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    399\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 400\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    401\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    402\u001b[0m             \u001b[0;32massert\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<eval_with_key>.14\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0medge_index__user__clicks__news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'user'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'clicks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'news'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0medge_index__news__rev_clicks__user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0medge_index_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'news'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rev_clicks'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'user'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0medge_index_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m     \u001b[0mconvs_0__news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser__clicks__news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__user__clicks__news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m     \u001b[0mconvs_0__user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"0\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnews__rev_clicks__user\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx__news\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx__user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__news__rev_clicks__user\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0mx__news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx__user\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m     \u001b[0mconvs_1__news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconvs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"1\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0muser__clicks__news\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconvs_0__user\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconvs_0__news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0medge_index__user__clicks__news\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m  \u001b[0medge_index__user__clicks__news\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1773\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1774\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1775\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1776\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1777\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1784\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1785\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1786\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1787\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1788\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x, edge_index, edge_attr, size, return_attention_weights)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m         \u001b[0;31m# propagate_type: (x: OptPairTensor, alpha: Tensor)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 366\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpropagate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0medge_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/tmp/torch_geometric.nn.conv.gat_conv_GATConv_propagate_2m94exk1.py\u001b[0m in \u001b[0;36mpropagate\u001b[0;34m(self, edge_index, x, alpha, size)\u001b[0m\n\u001b[1;32m    174\u001b[0m         \u001b[0;31m# End Message Forward Pre Hook #########################################\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 176\u001b[0;31m         out = self.message(\n\u001b[0m\u001b[1;32m    177\u001b[0m             \u001b[0mx_j\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx_j\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    178\u001b[0m             \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.12/dist-packages/torch_geometric/nn/conv/gat_conv.py\u001b[0m in \u001b[0;36mmessage\u001b[0;34m(self, x_j, alpha)\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    413\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 414\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mx_j\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    415\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    416\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__repr__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 998.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 244.12 MiB is free. Process 10445 has 14.50 GiB memory in use. Of the allocated memory 14.13 GiB is allocated by PyTorch, and 252.87 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "PrjP_JvKaWET"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}